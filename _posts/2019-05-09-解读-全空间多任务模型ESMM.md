---
layout:     post
title:      全空间多任务模型ESMM解读及实现
subtitle:   《Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate》By Alibaba @ SIGIR'18
date:       2019-05-09
author:     Mars
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 推荐系统
    - 计算广告
---

## 全空间多任务模型ESMM解读及实现

> 《Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate》By ***Alibaba @ SIGIR'18***

### 1. Paper Reading

#### 1.1 背景

在搜索、推荐系统、在线广告投放等工业级应用中，点击后转化率（Post-Click Conversion Rate, pCVR），是至关重要的，在电商平台的推荐系统中，最大商品交易总额（Gross Merchandise Volumn, GMV）是重要指标之一，而GMV可以由 $流量*点击率*转化率*客单价​$ 计算得出，可见**点击率、转化率**是优化目标的重要因子，从用户体验角度来说，准确预估的CVR被用来平衡用户的点击偏好与购买（转化）偏好。

阿里妈妈的这篇文章，提出了一种新颖的CVR预估模型，称之为**全空间多任务模型**，简称ESMM，其创新地利用了用户行为系列数据，在全样本空间（全空间-全曝光样本空间，而非曝光&点击空间）同时学习点击率和转化率（Post-view click through&conversion rate, CTCVR-多任务），解决了传统CVR预估模型中的样本选择偏差（Sample Selection Bias, SSB）和训练数据过于稀疏（Data Sparsity, DS）的问题。

从用户的行为角度看，***点击***曝光在眼前且感兴趣的商品，点击后根据商品价格、介绍、评价、自身需要等产生***购买***行为。因此用户的行为是遵循**曝光(Impression)->点击(Click)->转化(Conversion)**三个步骤的，传统CVR模型旨在预估用户在看到曝光的商品且进入到商品详情页，进而产生购买的的概率，即$pCVR=p(conversion|click, impression)​$。

#### 1.2 问题定义

假设训练数据集为$S=\{(x_i,y_i\rightarrow{z_i}) \}|_{i=1}^N​$，其中样本$(x,y\rightarrow{z})​$是从域$X \times {Y} \times{Z}​$ 中按照某种分布采样得到的（***什么分布？怎么采的***），$X​$ 是特征空间，$Y，Z​$ 是标签空间，$N​$ 是数据集中的样本总数量。$x​$ 是高维稀疏多域的特征向量， $y,z​$ 取值为0或1，分别表示是否点击和是否购买。$y \rightarrow z​$ 解释了用户行为的顺序性，CVR模型的目标是预估条件概率$pCVR​$，与其相关的两个概率为点击率$pCTR​$ 和 点击且转化率$pCTCVR​$，其关系如下：

$$p(y=1,z=1|x)=p(y=1|x)\times{p(z=1|y=1,x)}​$$，CVR建模通常采用类似CTR建模的技术，但区别于CTR，CVR建模所面临的一些挑战：1）样本选择偏差（**SSB**）；2）训练数据稀疏（**DS**）；3）延迟反馈；

- SSB，用户行为序列（曝光-点击-转化）中，CVR模型是在全空间的一个子集上进行训练的，基于子集构造的特征和基于全空间构造的特征是有偏的，尤其当子集相对于全空间很小时，特征提取结果是很不相同的，训练集是来自于真是分布不一致的分布中采样的，一定程度上违背了机器学习的前提假设：训练集和测试集必须独立地采样自同一个分布，独立同分布。因此用样本子集作为训练及对全空间进行预测的现象称之为**样本选择偏差**，会影响到模型的泛华性能。
- DS，全空间->点击空间->转化空间，样本量依次锐减，在淘宝的公开训练数据集上，点击空间只占全空间的4%，这就是训练数据稀疏的问题，高度稀疏的训练数据使得模型的学习变得相当困难。

#### 1.3 数据集

阿里妈妈团队从生产上采样了数据集（Product Dataset），并公开了一个子集（[Public Dataset](https://tianchi.aliyun.com/dataset/dataDetail?dataId=408&userId=1)），具体数据体量如下表：

|     Dataset     | #user | #item | #impression | #click | #conversion |
| :-------------: | :---: | ----- | ----------- | ------ | ----------- |
| Public Dataset  | 0.4M  | 4.3M  | 84M         | 3.4M   | 18K         |
| Product Dataset |  48M  | 23.5M | 8950M       | 324M   | 1774K       |

本数据集采集自手机淘宝移动客户端的推荐系统日志，其中包含点击和与之关联的转化数据，淘宝平台作为全球最大的在线零售电子商务平台，为提升其用户体验，通过推荐系统提供商品推荐服务，用户可以在浏览（impression）推荐结果中点击（click）感兴趣的商品，或者进一步对商品进行购买（conversion）。因此用户的行为可以抽象为一个序列模式：浏览 -> 点击 -> 购买。数据集中各样本的标签 $y​$ 和 $z​$ 字段的值分布，服从如下约束：

| 标签值域  | 是否合法 |
| --------- | -------- |
| y=0 & z=0 | 合法     |
| y=0 & z=1 | 非法     |
| y=1 & z=0 | 合法     |
| y=1 & z=1 | 合法     |

数据集由训练集（sample_train.tar.gz）和测试集（sample_test.tar.gz）两部分组成

- sample_train.tar.gz
  - sample_skeleton_train.csv(42300135 Records, 10GB)
  - common_features_train.csv(730600 Records, 8.0GB)
- sample_test.tar.gz
  - sample_skeleton_test.csv(43016840 Records, 10GB)
  - common_features_test.csv(884212 Records, 10GB)

训练集和测试集严格按照时间顺序划分，训练数据先于测试数据发生，每部分数据由两个CSV格式文件构成：一个是样本骨架文件，另一个是公共特征文件，使用前确保骨架文件和公共特征文件已经进行正确地关联。关联方法：

``` sql
SELECT a.labels,a.features,b.features
FROM sample_skeleton_file AS a
LEFT JOIN common_features_file AS b
ON a.common_feature_index=b.common_feature_index;
```

**Sample Skeleton**

每一条记录代表一次用户浏览，并且由三个部分组成：

- 样本ID部分，唯一标识，样本骨架中的一条记录，取值从1开始直到全部样本数，是样本骨架文件的主键；

- 标签部分，标签部分包含一次浏览记录上的两种类型的标签信息：点击和转化事件是否发生，表1对取值范围进行了描述；

- 特征部分，包含三个域：

  - 索引域（common_feature_index）：作为样本骨架文件的外键，用来关联公共特征文件中的信息，复原样本时使用；

  - 特征数量域（feature_num）：指出本条记录中特征列表（feature_list）域包含的特征总数，是一个非负整数；

  - 特征列表（feature_list）域：由ASCII字符0x01分割的若干特征组成，这些特征由特征数据结构（Feature Structure）描述。特征数据结构由ASCII字符0x02和0x03作为分隔符的字符串构成，例如：feature_field_id *0x02* feature_id *0x03* feature_value，其中feature_field_id字段代表特征域信息，下表中进行了详细描述；feature_id字段是被全局编码后的特征ID值；feature_value字段是特征ID对应的特征值。

    | 特征域名称 | 特征域ID | 特征域说明                                     |
    | ---------- | -------- | ---------------------------------------------- |
    | 用户域     | 101      | 用户ID                                         |
    |            | 109_14   | 商品类目ID以及用户在该类目上的历史行为累积数量 |
    |            | 110_14   | 商品店铺ID以及用户在该店铺上的历史行为累积数量 |
    |            | 127_14   | 商品品牌ID以及用户在该品牌上的历史行为累积数量 |
    |            | 150_14   | 用户意图ID以及用户在该意图上的历史行为累积数量 |
    |            | 121      | 用户的一种分类ID                               |
    |            | 122      | 用户的一种分类ID                               |
    |            | 124      | 用户性别分类ID                                 |
    |            | 125      | 用户年龄分类ID                                 |
    |            | 126      | 用户消费水平分类I                              |
    |            | 127      | 用户消费水平分类II                             |
    |            | 128      | 用户是否就业                                   |
    |            | 129      | 用户地理信息分类ID                             |
    | 商品域     | 205      | 商品ID                                         |
    |            | 206      | 商品所属类目ID                                 |
    |            | 207      | 商品所属店铺ID                                 |
    |            | 210      | 商品关联用户意图ID                             |
    |            | 216      | 商品的品牌ID                                   |
    | 组合域     | 508      | 109_14和206域的组合特征                        |
    |            | 509      | 110_14和207域的组合特征                        |
    |            | 702      | 127_14和216域的组合特征                        |
    |            | 853      | 150_14和210域的组合特征                        |
    | 场景域     | 301      | 业务场景信息的一种分类表示                     |

    *用户历史行为信息来自过去两周*

**Common Features**

公共特征文件中的一条记录代表一个特定的特征集合，这个特征集合被样本骨架文件中若干条记录共享。在公共特征文件中同样存在common_feature_index作为*主键*，与样本骨架文件中的同名字段共同描述这种共享关系。

#### 1.4 ESMM

##### 1.4.1 ESMM的结构

ESMM的两个主要创新点：

- 多任务学习，引入了两个辅助学习任务，分别用来拟合$pCTR$ 和 $pCTCVR$，从而消除样本选择偏差及数据稀疏性。
- 充分利用用户行为序列进行建模。

![img](./esmm.png)

上图是ESMM模型的结构图，Base模型的网络**输入**包括 *user field* 和 *item field* 两部分，*user field​* 主要由用户的历史行为序列构成，包含了用户浏览的商品ID列表，以及用户浏览的品牌ID、类目ID列表等；不同的实体ID列表构成不同的field。**Embedding Layer**把这些实体ID都映射为固定长度的低维实数向量；接着之后的**Field-wise Pooling Layer**把同一个Field的所有实体Embedding向量求和得到对应于当前Field的一个一维向量；之后所有的Field的向量拼接**Concatenate**在一起构成一个大的隐层向量；接着大的隐层向量之上再接入若干全连接层，最后再链接到只有一个神经元的输出层。

##### 1.4.2 ESMM的两个特点

对于一个给定的展现，ESMM模型能够同时输出预估的 $pCTR, pCVR, pCTCVR$， 主要由两个子神经网络组成，左边的子网络（Main Task）用来拟合 $pCVR$，右边的子网络（Auxiliary Tasks）用来拟合 $pCTR$，两个网络结果完全相同，论文中将子网络命名为**Base模型（Embedding+MLP）**，两个子网络的输出结果相乘之后即得到 $pCTCVR$，ESMM模型有两个特点值得强调，正是因此而区别于传统的CVR预估模型：

1. **在整个样本空间中建模（Entire-Space）**。$pCVR​$ 可以先估计出 $pCTR​$ 和 $pCTCVR​$ 之后推导出来，从原理上来说，相当于分别单独训练两个模型拟合 $pCTR​$ 和 $pCTCVR​$，再通过 $pCTCVR​$ 除以 $pCTR​$ 得到最终的拟合目标 $pCVR​$，具体如下面的公式：$p(z=1|y=1,x)=\frac{p(y=1,z=1|x)}{p(y=1|x)}​$，但由于 $pCTR​$ 通常很像，除以一个很小的浮点数容易引起数组不稳定（计算内存溢出），所以ESMM模型采用了乘法的方式，而么有采用除法的方式；这里 $pCTR​$ 和 $pCTCVR​$ 是ESMM模型需要估计的两个主要因子，而且是通过在全空间进行建模得到的， $pCVR​$ 只是一个中间变量。
2. **共享特征表示**。ESMM模型借鉴迁移学习的思路，在两个子网络的**Embedding层共享Embedding向量（特征表示）词典**。网络的Embedding层把大规模稀疏的输入数据映射到低维的表示向量，该层的参数占了整个网络参数的绝大部分，需要大量的训练样本才能充分学习到。由于CTR任务的训练样本要大大超过CVR任务的训练样本，ESMM模型中的特征表示共享机制能够使得CVR子任务也能够从只有展现没有点击的样本中学习，从而能够极大地有利于缓解训练数据的稀疏性问题。

##### 1.4.3 ESMM的损失函数

ESMM模型的损失函数由两个部分组成，对应于 $pCTR$ 和 $pCTCVR$ 两个子任务：

$L(\theta_{cvr},\theta_{ctr})=\sum_{i=1}^{N}l(y_i,f(x_i;\theta_{ctr}))+\sum_{i=1}^{N}l(y_i\&z_i,f(x_i;\theta_{ctr})\times f(x_i;\theta_{cvr}))​$

其中，$\theta_{ctr}​$ 和 $\theta_{cvr}​$ 分别是CTR网络和CVR网络的参数，$l(\cdot)​$ 是交叉熵损失函数， 在CTR任务中，有点击行为的曝光事件构成的样本标记为正样本，没有点击行为发生的曝光事件标记为负样本；在CTCVR任务中，同时有点击和购买行为的曝光事件标记为正样本，否则标记为负样本；

在生产数据上的CVR和CTCVR子任务效果对比图：

![img](./comparison-product.png)

通常AUC指标提升0.1%就可认为是一个显著的改进。

### 2. 模型实现

#### 2.1 Base Model

##### 2.1.1 Feature Column构建序列Embedding和Pooling

前文对[ESMM模型结构](#1.4-ESMM)进行了详细描述，这部分主要是基于TensorFlow进行实现，用Tensorflow中的[Feature Column API](https://zhuanlan.zhihu.com/p/41663141)可以非常容易地实现**Embedding Layer和Field-wise Pooling Layer**。

- **Embedding Layer**的实现，需要用到 *tf.feature_column.embedding_column* 或者 *tf.feature_column.shared_embedding_columns*，在推荐场景中，希望 *user field​* 和 *item field* 的同一类型的实体共享相同的Embedding映射空间，所以选用 *tf.feature_column.shared_embedding_columns*，由于 *shared_embedding_columns* 函数只接受 categorical_column列表作为参数，因此需要为原始特征数据先创建categorical_columns。假设在原始特征数据中，behaviorPids表示用户历史浏览过的产品ID列表；ProductID表示当前的候选产品ID；则构建Embedding Layer的代码如下:

  ``` python
  from tensorflow import feature_column as fc
  # user field
  pids = fc.categorical_column_with_hash_bucket("behaviorPids", 10240, dtype=tf.int64)
  # item field
  pid = fc.categorical_column_with_hash_bucket("productId", 100000, dtype=tf.int64)
  
  pid_embed = fc.shared_embedding_columns([pids,pid], 100, combiner='sum', share_embedding_collection_name="pid")
  ```

  **注意**：构建训练样本时，behaviorPids列表必须是固定长度的，否则在使用dataset的batch方法时会报tensor shape不一致的错，然而，现实中每个用户浏览过的产品个数肯定不一样，这是可以截取用户的最近N个浏览行为，当某些用户的浏览商品数不足N个时填充默认值-1（若ID是用字符串表示的，就填充空字符串），填充-1是因为categorical_column*函数用默认值-1表示样本数据中未登录的值，-1表示categorical_column经过embedding_column之后被映射到零向量，而零向量在后面的求和Pooling操作中不影响结果。

- **Field-wise Pooling Layer**，在用tf.feature_column.embedding_column或者tf.feature_column.shared_embedding_columns API时不需要另外实现Pooling Layer，因为这两个函数同时实现了**Embedding向量映射**和**field-wise pooling**，上面代码中的shared_embedding_columns函数的combiner='sum'，这个参数指明了当该Field有多个Embedding向量时融合为唯一一个向量的操作，'sum'操作即为element-wise add。

##### 2.1.2 实现Weighted Sum Pooling操作

上小节实现了行为序列特征的Embedding和Pooling，但序列中的每个行为被同等对待了；某些情况下可能希望的是行为序列中不同的实体ID在做Sum Pooling时有不同的权重。比如用户行为时间越近的产品权重越高，或者候选产品有相同属性的产品有更高的权重。要实现Weighted Sum Pooling，使用的是weighted_categorical_column函数，必须在构建样本时添加一个额外的**权重特征**，权重特征表示行为序列中每个产品的权重，因此券中特着是一个与行为序列平行的列表（向量），两者的维度必须相同，如果行为序列中有填充的默认值-1，则对应到权重特征中的权重必须为0。代码示例如下：

``` python
from tensorflow import feature_column as fc
# user field
pids = fc.categorical_column_with_hash_bucket("behaviorPids", 10240, dtype=tf.int64)
pids_weighted = fc.weighted_categorical_column(pids, "pidWeights")
# item field
pid = fc.categorical_column_with_hash_bucket("productId", 1000000, dtype=tf.int64)

pid_embed = fc.shared_embedding_columns([pids_weighted, pid],100,combiner='sum',share_embedding_collection_name="pid")
```

##### 2.1.3 模型函数

Base模型的模型函数如下：

``` python
def my_model(features, labels, mode, params):
    net = fc.input_layer(features, params['feature_columns'])
    # Build the hidden layers, sized according to the 'hidden_units' param.
    for units in params['hidden_units']:
        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)
        if 'dropout_rate' in params and params['dropout_rate'] > 0.0:
            net = tf.layers.dropout(net, params['dropout_rate'], training=(mode == tf.estimator.ModeKeys.TRAIN))
    my_head = tf.contrib.estimator.binary_classification_head(thresholds=[0.5])
    # Compute logits(1 per class).
    logits = tf.layers.dens(net, my_head.logits_dimension, activation=None, name="my_model_output_logits")
    optimizer = tf.train.AdagradOptimizer(learning_rate=params['learning_rate'])
    
	def _train_op_fn(loss):
    	return optimizer.minimize(loss, global_step=tf.train.get_global_step())

	return my_head.create_estimator_spec(
    	features = features,
        mode = mode,
        labels = labels,
        logits = logits,
        train_op_fn = _train_op_fn
    )
```

#### 2.2 ESMM Model

在实现ESMM模型时没有现成的Head API可用，必须手动创建*EstimatorSpec*，在不同的Mode下，模型函数必须返回包含不同图操作（op）的EstimatorSpec，具体的：

- For mode == ModeKeys.TRAIN: required fields are **loss** and **train_op**
- For mode == ModeKeys.EVAL: required field is **loss**
- For mode == ModeKyes.PREDICT: required fields are **predictions**

若模型需要导出以便提供线上服务，这时必须在mode==ModeKeys.EVAL定义export_outputs操作，并添加到返回的EstimatorSpec中。实现ESMM模型的关键在于定义该模型独特的[损失函数](#1.4.3-ESMM的损失函数)，由两部分组成，一部分对应于CTR任务，另一个部分对应于CTCVR任务。具体定义的代码如下:

``` python
def build_mode(features, mode, params):
    net = fc.input_layer(features, params['feature_columns'])
    # Build the hidden layers, sized according to the 'hidden_units' param.
    for units in params['hidden_units']:
        net = tf.layers.dens(net, units = units, activation=tf.nn.relu)
        if 'dropout_rate' in params and params['dropout_rate'] > 0.0:
            net = tf.layers.dropout(net, params['dropout_rate'], training = (mode==tf.estimator.ModeKeys.TRAIN))
            
    # Compute Logits
    logits = tf.layers.dense(net, 1, activation=None)
    return logits

def my_model(features, labels, mode, params):
    with tf.variable_scope('ctr_model'):
        ctr_logits = build_mode(features, mode, params)
    with tf.variable_scope('cvr_model'):
        cvr_logits = build_mode(features, mode, params)
        
    ctr_predictions = tf.sigmoid(ctr_logits, name="CTR")
    cvr_predictions = tf.sigmoid(cvr_logits, name="CVR")
    prop = tf.multiply(ctr_predictions, cvr_predictions, name="CTCVR")
    
    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {
            'probabilities': prop,
            'ctr_probabilities': ctr_predictions,
            'cvr_probabilities': cvr_predictions
        }
        export_outputs = {
            'prediction': tf.estimator.export.PredictOutput(predictions)
        }
        return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)
    
    y = labels['cvr']
    cvr_loss = tf.reduce_sum(tf.keras.backend.binary_crossentropy(y,prop),name = 'cvr_loss')
    ctr_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels['ctr'], logits=ctr_logits), name="ctr_loss")
    loss = tf.add(ctr_loss, cvr_loss, name="ctcvr_loss")
    
    ctr_accuracy = tf.metrics.accuracy(labels=labels['ctr'], predictions=tf.to_float(tf.greater_equal(ctr_predictions, 0.5)))
    cvr_accuracy = tf.metrics.accuracy(labels=y, predictions=tf.to_float(tf.greater_equal(prop, 0.5)))
    
    ctr_auc = tf.metrics.auc(labels['ctr'], ctr_predictions)
    cvr_auc = tf.metrics.auc(y, prop)
    metrics = {'cvr_accuracy': cvr_accuracy, 'ctr_accuracy': ctr_accuracy, 'ctr_auc': ctr_auc, 'cvr_auc': cvr_auc}
    tf.summary.scalar('ctr_accuracy', ctr_accuracy[1])
    tf.summary.scalar('cvr_accuracy', cvr_accuracy[1])
    tf.summary.scalar('ctr_auc', ctr_auc[1])
    tf.summary.scalar('cvr_auc', cvr_auc[1])
    
    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)
    
    # Create training Op.
    assert mode == tf.estimator.ModeKeys.TRAIN
    optimizer = tf.train.AdagradOptimizer(learning_rate=params['learning_rate'])
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)
    
```

> ESMM复现，未完待续......

---------

### Reference

1. [完整空间多任务模型：CVR预估的有效方法](http://xudongyang.coding.me/esmm/)
2. [精读&解析 Entire Space Multi-Task Model（ESMM） 阿里2018年CVR预测](https://blog.csdn.net/sinat_15443203/article/details/83713802)
3. [构建分布式Tensorflow模型系列之CVR预估案例ESMM模型](http://xudongyang.coding.me/esmm-1/)
4. [构建分布式Tensorflow模型系列:特征工程](https://zhuanlan.zhihu.com/p/41663141)
5. [ESMM源码-阿里杨旭东](https://github.com/yangxudong/deeplearning/tree/master/esmm)
